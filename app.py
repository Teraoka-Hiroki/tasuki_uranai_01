import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import matplotlib.font_manager as fm

# ---------------------------------------------------------
# ãƒšãƒ¼ã‚¸è¨­å®š
# ---------------------------------------------------------
st.set_page_config(page_title="Moodleã‚³ãƒ¼ã‚¹ ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã‚¢ãƒ—ãƒª", layout="wide")

# ---------------------------------------------------------
# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆä¿®æ­£ç‰ˆï¼‰
# ---------------------------------------------------------
def configure_japanese_font():
    """
    æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’é©ç”¨ã—ã€æˆåŠŸã—ãŸã‹ã©ã†ã‹ã‚’è¿”ã™é–¢æ•°ã€‚
    Seabornã®ãƒ†ãƒ¼ãƒè¨­å®šã«ã‚‚ãƒ•ã‚©ãƒ³ãƒˆã‚’æ˜ç¤ºçš„ã«æ¸¡ã™ã“ã¨ã§æ–‡å­—åŒ–ã‘ã‚’é˜²ãã€‚
    """
    # 1. japanize_matplotlib (æœ€å„ªå…ˆ)
    try:
        import japanize_matplotlib
        japanize_matplotlib.japanize()
        # ã€é‡è¦ã€‘Seabornã®ãƒ†ãƒ¼ãƒè¨­å®šã«ãƒ•ã‚©ãƒ³ãƒˆåã‚’æ˜ç¤ºçš„ã«æ¸¡ã™
        sns.set_theme(style="whitegrid", font="IPAexGothic")
        return True, "IPAexGothic"
    except ImportError:
        pass

    # 2. ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆæ¢ç´¢ï¼ˆjapanize_matplotlibãŒãªã„å ´åˆã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
    target_fonts = [
        'Noto Sans CJK JP', 'Noto Sans JP', 'Hiragino Sans', 
        'Hiragino Kaku Gothic ProN', 'Yu Gothic', 'Meiryo', 
        'TakaoGothic', 'IPAGothic', 'IPAexGothic', 'VL Gothic', 'MS Gothic'
    ]
    
    # ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—
    available_fonts = {f.name for f in fm.fontManager.ttflist}
    
    found_font = None
    for font in target_fonts:
        if font in available_fonts:
            found_font = font
            break
            
    if found_font:
        # Matplotlibã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’æ›´æ–°
        plt.rcParams['font.family'] = found_font
        # Seabornã®ãƒ†ãƒ¼ãƒè¨­å®šã«ã‚‚ãƒ•ã‚©ãƒ³ãƒˆã‚’é©ç”¨
        sns.set_theme(style="whitegrid", font=found_font)
        return True, found_font

    # 3. ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    # è‹±èªè¨­å®šã®ã¾ã¾ã«ã™ã‚‹ãŒã€æœ€ä½é™Seabornã®ã‚¹ã‚¿ã‚¤ãƒ«ã¯é©ç”¨
    sns.set_theme(style="whitegrid")
    return False, None

# è¨­å®šã‚’å®Ÿè¡Œ
FONT_AVAILABLE, USED_FONT = configure_japanese_font()

# ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆä¸è¦ãªã‚‰ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
if FONT_AVAILABLE:
    # st.toast(f"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆé©ç”¨ä¸­: {USED_FONT}", icon="âœ…")
    pass
else:
    st.toast("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è‹±èªãƒ¢ãƒ¼ãƒ‰ã§è¡¨ç¤ºã—ã¾ã™ã€‚", icon="âš ï¸")

# ãƒã‚¤ãƒŠã‚¹è¨˜å·ã®æ–‡å­—åŒ–ã‘å¯¾ç­–
plt.rcParams['axes.unicode_minus'] = False

# ---------------------------------------------------------
# 0. ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆCSVãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
# ---------------------------------------------------------
def create_dummy_csv():
    data = {
        'Cluster': [0, 0, 1, 1, 2, 2, 3, 3, 4, 4],
        'Factor1_Score': [2.5, 2.0, 1.5, 1.8, -2.0, -1.5, 0.0, 0.2, -2.5, -1.8],
        'Factor2_Score': [-1.5, -2.0, 2.0, 1.5, 1.0, 1.5, 0.1, -0.1, -2.0, -1.5],
        'ã‚³ãƒ¼ã‚¹åï¼ˆçŸ­ç¸®ï¼‰': [
            'é«˜åº¦AIç†è«–', 'ç”ŸæˆAIå®Ÿè£…ç‰¹è«–', 'çµ±è¨ˆæ•°å­¦åŸºç¤', 'ãƒ‡ãƒ¼ã‚¿åˆ†æå…¥é–€',
            'Webé–‹ç™ºåŸºç¤', 'Linuxã‚µãƒ¼ãƒãƒ¼æ§‹ç¯‰', 'æƒ…å ±ãƒªãƒ†ãƒ©ã‚·ãƒ¼', 'ITãƒ‘ã‚¹ãƒãƒ¼ãƒˆå¯¾ç­–',
            'Reactã‚¢ãƒ—ãƒªé–‹ç™º', 'æœ€æ–°APIæ´»ç”¨'
        ],
        'è©•ä¾¡ã®æ ¹æ‹ ã¨ç‰¹è¨˜äº‹é …': [
            'æœ€æ–°è«–æ–‡ã®è¼ªèª­ã‚’è¡Œã„ã¾ã™', 'LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°', 'ç¢ºç‡çµ±è¨ˆã®åŸºç¤ã‹ã‚‰', 'Pythonã§ã®ãƒ‡ãƒ¼ã‚¿æ“ä½œ',
            'HTML/CSS/JSã®åŸºç¤', 'ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³æ“ä½œ', 'PCã®åŸºæœ¬æ“ä½œ', 'è³‡æ ¼å–å¾—å‘ã‘',
            'ãƒ¢ãƒ€ãƒ³ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰', 'ç”ŸæˆAI APIã®æ´»ç”¨'
        ],
        'Recommended_Order': [1, 2, 1, 2, 1, 2, 1, 2, 1, 2]
    }
    df = pd.DataFrame(data)
    df.to_csv('course_learning_path.csv', index=False)
    return df

# ---------------------------------------------------------
# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨åˆæœŸè¨­å®š
# ---------------------------------------------------------
@st.cache_data
def load_data():
    csv_file = 'course_learning_path.csv'
    if not os.path.exists(csv_file):
        return create_dummy_csv()
    try:
        df = pd.read_csv(csv_file)
        return df
    except Exception:
        return pd.DataFrame()

df = load_data()

if df.empty:
    st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    st.stop()

# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼IDã¨ã‚¿ã‚¤ãƒ—åã®å®šç¾©
CLUSTER_NAMES = {
    0: "AIç ”ç©¶è€…ãƒ»ãƒãƒƒã‚«ãƒ¼ (ç†è«–Ã—å¿œç”¨)",
    1: "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹åŸºç¤ (ç†è«–Ã—åŸºç¤)",
    2: "ITã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢åŸºç¤ (WebÃ—åŸºç¤)",
    3: "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ãƒ»ç·åˆ (ãƒãƒ©ãƒ³ã‚¹å‹)",
    4: "AIã‚¢ãƒ—ãƒªã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ (WebÃ—å¿œç”¨)"
}

CLUSTER_DESC = {
    0: "é«˜åº¦ãªæ•°ç†ãƒ¢ãƒ‡ãƒ«ã¨æœ€æ–°ã®ç”ŸæˆAIæŠ€è¡“ã®ä¸¡æ–¹ã‚’æ·±ãæ¢ç©¶ã—ãŸã„ã€ç ”ç©¶å¿—å‘ã®ã‚ãªãŸã«ãŠã™ã™ã‚ã§ã™ã€‚",
    1: "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚„æ•°å­¦çš„èƒŒæ™¯ã‚’ã—ã£ã‹ã‚Šå›ºã‚ãŸã„ã€ç†è«–é‡è¦–ã®ã‚ãªãŸã«ãŠã™ã™ã‚ã§ã™ã€‚",
    2: "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚„Webã®ä»•çµ„ã¿ãªã©ã€ITã®åŸºç¤ä½“åŠ›ã‚’ã¤ã‘ãŸã„ã‚ãªãŸã«ãŠã™ã™ã‚ã§ã™ã€‚",
    3: "ã¾ãšã¯åã‚Šãªãã€AIãƒ»æƒ…å ±ã®åŸºç¤ã‹ã‚‰å¿œç”¨ã¾ã§ã‚’ãƒãƒ©ãƒ³ã‚¹ã‚ˆãå­¦ã³ãŸã„ã‚ãªãŸã«ãŠã™ã™ã‚ã§ã™ã€‚",
    4: "ç†å±ˆã‚ˆã‚Šã‚‚ã¾ãšã¯å‹•ãã‚‚ã®ã‚’ï¼æœ€æ–°ã®ç”ŸæˆAIã‚„WebæŠ€è¡“ã‚’ä½¿ã£ã¦ã‚¢ãƒ—ãƒªã‚’ä½œã‚ŠãŸã„ã‚ãªãŸã«ãŠã™ã™ã‚ã§ã™ã€‚"
}

# ---------------------------------------------------------
# 2. ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå…¥åŠ›
# ---------------------------------------------------------
st.sidebar.header("ğŸ” ã‚ãªãŸã®èˆˆå‘³ãƒ»é–¢å¿ƒ")
st.sidebar.write("ä»¥ä¸‹ã®è³ªå•ã«ç­”ãˆã¦ã€ã‚ãªãŸã«ã´ã£ãŸã‚Šã®å­¦ç¿’ã‚³ãƒ¼ã‚¹ã‚’è¦‹ã¤ã‘ã¾ã—ã‚‡ã†ã€‚")

st.sidebar.markdown("---")

q1 = st.sidebar.slider(
    "Q1. èˆˆå‘³ãŒã‚ã‚‹ã®ã¯ã©ã£ã¡ï¼Ÿ",
    min_value=-3.0, max_value=3.0, value=0.0, step=0.5,
    help="å·¦ï¼šWebãƒ»ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º ï¼ å³ï¼šæ•°å­¦ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ†æ"
)
st.sidebar.caption("Webãƒ»ã‚¢ãƒ—ãƒªé–‹ç™º âŸµ ã€€ âŸ¶ æ•°å­¦ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ†æ")

st.sidebar.markdown("---")

q2 = st.sidebar.slider(
    "Q2. å­¦ç¿’ã‚¹ã‚¿ã‚¤ãƒ«ã®å¥½ã¿ã¯ï¼Ÿ",
    min_value=-3.0, max_value=3.0, value=0.0, step=0.5,
    help="å·¦ï¼šæœ€æ–°AIæ´»ç”¨ãƒ»å®Ÿè·µ ï¼ å³ï¼šæ•™ç§‘æ›¸ãƒ»åŸºç¤ç†è§£"
)
st.sidebar.caption("ç”ŸæˆAIãƒ»å®Ÿè·µ âŸµ ã€€ âŸ¶ æ•™ç§‘æ›¸ãƒ»åŸºç¤")

user_vector = np.array([q1, q2])

# ---------------------------------------------------------
# 3. ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ï¼šãƒãƒƒãƒãƒ³ã‚°
# ---------------------------------------------------------
centroids = df.groupby('Cluster')[['Factor1_Score', 'Factor2_Score']].mean()

distances = {}
for cluster_id, row in centroids.iterrows():
    centroid_vector = np.array([row['Factor1_Score'], row['Factor2_Score']])
    dist = np.linalg.norm(user_vector - centroid_vector)
    distances[cluster_id] = float(dist)

best_cluster_id = min(distances, key=distances.get)

try:
    best_cluster_key = int(best_cluster_id)
except (ValueError, TypeError):
    best_cluster_key = best_cluster_id

best_cluster_name = CLUSTER_NAMES.get(best_cluster_key, f"Cluster {best_cluster_id}")

# ---------------------------------------------------------
# 4. çµæœè¡¨ç¤ºç”»é¢
# ---------------------------------------------------------
st.markdown("## ãƒ†ãƒ©ã‚ªã‚«é›»å­ã®Moodleã‚³ãƒ¼ã‚¹ ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã‚¢ãƒ—ãƒª")
st.markdown("# ã€ã‚¿ã‚¹ã‚¯å ã„ã€")
st.title("ğŸ“ ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰çµæœ")

col1_container = st.container()
with col1_container:
    st.subheader(f"ã‚ãªãŸã¯... **ã€Œ{best_cluster_name}ã€** ã‚¿ã‚¤ãƒ—ã§ã™ï¼")
    st.info(CLUSTER_DESC.get(best_cluster_key, ""))

    st.markdown("### ğŸš€ æ¨å¥¨å­¦ç¿’ãƒ«ãƒ¼ãƒˆ")
    st.write("ä»¥ä¸‹ã®é †åºã§å­¦ã¶ã¨ã€çŸ¥è­˜ã‚’åŠ¹ç‡ã‚ˆãç©ã¿ä¸Šã’ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")

    target_courses = df[df['Cluster'].astype(str) == str(best_cluster_id)].sort_values('Recommended_Order')

    if target_courses.empty:
        st.write("è©²å½“ã™ã‚‹æ¨å¥¨ã‚³ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        for i, (idx, row) in enumerate(target_courses.iterrows(), 1):
            with st.expander(f"{i}. {row['ã‚³ãƒ¼ã‚¹åï¼ˆçŸ­ç¸®ï¼‰']}"):
                st.write(f"**å†…å®¹:** {row.get('è©•ä¾¡ã®æ ¹æ‹ ã¨ç‰¹è¨˜äº‹é …', 'è©³ç´°ãªã—')}")
                st.write(f"**åˆ†é‡ã‚¹ã‚³ã‚¢:** ç†è«–åº¦ {row['Factor1_Score']:.2f} / åŸºç¤åº¦ {row['Factor2_Score']:.2f}")

st.markdown("---")

col2_container = st.container()
with col2_container:
    st.markdown("### ğŸ—ºï¸ ã‚³ãƒ¼ã‚¹ãƒãƒƒãƒ—")

    fig, ax = plt.subplots(figsize=(8, 8))

    # å…¨ã‚³ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒƒãƒˆ
    sns.scatterplot(
        data=df, x='Factor1_Score', y='Factor2_Score',
        hue='Cluster', palette='bright', alpha=0.4, s=100,
        ax=ax, legend=False
    )

    # æ¨å¥¨ã‚³ãƒ¼ã‚¹
    if not target_courses.empty:
        sns.scatterplot(
            data=target_courses, x='Factor1_Score', y='Factor2_Score',
            color='red', s=150, marker='o', label='æ¨å¥¨ã‚³ãƒ¼ã‚¹', ax=ax
        )

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½ç½®
    ax.scatter(
        user_vector[0], user_vector[1],
        color='gold', s=400, marker='*', edgecolor='black',
        label='ã‚ãªãŸ', zorder=10
    )

    ax.axhline(0, color='gray', linestyle='--')
    ax.axvline(0, color='gray', linestyle='--')
    
    # è»¸ãƒ©ãƒ™ãƒ«ã®è¨­å®š
    if FONT_AVAILABLE:
        ax.set_xlabel("Webãƒ»ã‚·ã‚¹ãƒ†ãƒ  <---> ç†è«–ãƒ»æ•°å­¦")
        ax.set_ylabel("ç”ŸæˆAIãƒ»å¿œç”¨ <---> åŸºç¤ãƒ»æ•™ç§‘æ›¸")
        ax.set_title("ã‚ãªãŸã®ç«‹ã¡ä½ç½®")
        # å‡¡ä¾‹ã®è¨­å®šï¼ˆãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’å†æŒ‡å®šã—ã¦ãƒ€ãƒ¡æŠ¼ã—ï¼‰
        ax.legend(prop={'family': USED_FONT})
    else:
        ax.set_xlabel("Web <---> Theory")
        ax.set_ylabel("GenAI <---> Basic")
        ax.set_title("Your Position (Japanese Font Missing)")
        ax.legend()

    st.pyplot(fig)